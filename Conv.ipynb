{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from Data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution2D:\n",
    "    def __init__(self, kernel_size, Cin, Cout, Stride = 1, Padding = 0):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.Cin = Cin\n",
    "        self.Cout = Cout\n",
    "        self.Stride = Stride\n",
    "        self.Padding = Padding\n",
    "        self.W = {\"data\" : np.random.normal(0.0, (2/Cin), (Cout, Cin, kernel_size, kernel_size)), \"delta\" : 0}\n",
    "        self.b = {\"data\" : np.random.randn((self.Cout)), \"delta\": 0}\n",
    "\n",
    "        self.input = {\"data\": None, \"delta\": None}\n",
    "        self.output = {\"data\" : None, \"delta\": None}\n",
    "\n",
    "\n",
    "    def forward_propogation(self, input):\n",
    "        self.input[\"data\"] = input\n",
    "        self.output[\"data\"] = self.correlation(input, self.W[\"data\"])\n",
    "        return self.output[\"data\"]\n",
    "\n",
    "    def backward_propogation(self, dy):\n",
    "        self.output[\"delta\"] = dy\n",
    "        M, Cin, H, _ = self.input[\"data\"].shape\n",
    "        o = np.zeros((self.W[\"data\"].shape))\n",
    "        for i in range(o.shape[2]):\n",
    "            for j in range(o.shape[3]):\n",
    "                bKernel = np.zeros((M, self.Cout, self.Cin, H, H))\n",
    "                if i + dy.shape[-1] < bKernel.shape[3] and j + dy.shape[-1] < bKernel.shape[4]:\n",
    "                    bKernel[:, :, :, i : (i + dy.shape[-1]), j : (j + dy.shape[-1])] = dy[:, :, np.newaxis, :, :]\n",
    "                    temp = (self.inputs[:, np.newaxis, :, :, :] * bKernel).sum((0, 3, 4))\n",
    "                    o[:, :, i, j] = temp\n",
    "        self.W[\"delta\"] = o\n",
    "        # self.W[\"grad\"] = self.convolution(self.inputs, dy)\n",
    "        self.b[\"delta\"] = np.sum(dy, axis=(2, 3))\n",
    "        self.dx = self.convolution(dy, np.rot90(np.rot90(self.W[\"data\"], axes=(2, 3)), axes=(2, 3)))\n",
    "\n",
    "        self.W[\"data\"] = self.W[\"data\"] - 0.01 * self.W[\"grad\"]\n",
    "        self.b[\"data\"] = self.b[\"data\"] - 0.01 * self.b[\"grad\"]\n",
    "        return self.dx\n",
    "\n",
    "    def convolution(self, dy, kernel):\n",
    "        M, Cin, H, _ = self.inputs.shape\n",
    "        output = np.zeros((self.inputs.shape))\n",
    "        for i in range(self.inputs.shape[2]):\n",
    "            for j in range(self.inputs.shape[3]):\n",
    "                bKernel = np.zeros((M, self.Cout, self.Cin, dy.shape[-1], dy.shape[-1]))\n",
    "                if i + self.kernel_size <= bKernel.shape[3] and j + self.kernel_size <= bKernel.shape[4]:\n",
    "                    bKernel[:, :, :, i : (i + kernel.shape[-1]), j : (j + kernel.shape[-1])] = kernel[np.newaxis, :, :, :, :]\n",
    "                    temp = (dy[:, :, np.newaxis, :, :] * bKernel)\n",
    "                    temp = temp.sum((1, 3, 4))\n",
    "                    output[:, :, i, j] = temp.reshape(temp.shape[0], temp.shape[1])\n",
    "        return output\n",
    "\n",
    "\n",
    "    def correlation(self, input, kernel):\n",
    "        M, Cin, H, _ = input.shape\n",
    "        new_h = int((H - self.kernel_size + 2 * self.Padding) / self.Stride + 1)\n",
    "        output = np.zeros((M, self.Cout, new_h, new_h))\n",
    "        for i in range(output.shape[2]):\n",
    "            for j in range(output.shape[3]):\n",
    "                bKernel = np.zeros((M, self.Cout, self.Cin, H, H))\n",
    "                if i + self.kernel_size <= bKernel.shape[3] and j + self.kernel_size <= bKernel.shape[4]:\n",
    "                    bKernel[:, :, :, i : (i + self.kernel_size), j : (j + self.kernel_size)] = kernel[np.newaxis, :, :, :, :]\n",
    "                    temp = (input[:, np.newaxis, :, :, :] * bKernel).sum((2, 3, 4))\n",
    "                    output[:, :, i, j] = temp.reshape(temp.shape[0], temp.shape[1])\n",
    "        return output\n",
    "\n",
    "# class FC:\n",
    "#     def __init__(self, n_nodes, n_output, learning_rate):\n",
    "#         self.n_nodes = n_nodes\n",
    "#         #  np.random.randn(n_output, n_nodes) np.random.normal(0.0, 0.5, (n_output, n_nodes))\n",
    "        \n",
    "#         self.W = {\"data\" :  1/np.sqrt(n_nodes / 2.) * np.random.randn(n_nodes, n_output), \"delta\" : np.zeros((n_output, n_nodes))}\n",
    "#         self.b = {\"data\": np.random.normal(0.0, 0.1, (1, n_output)) / np.sqrt(n_output), \"delta\" : np.zeros((1))}\n",
    "#         self.Y = {\"data\": 0, \"delta\": 0}\n",
    "#         self.learning_rate = learning_rate\n",
    "        \n",
    "#     def forward_propogation(self, inputs):\n",
    "#         self.inputs = inputs\n",
    "#         self.Y[\"data\"] = np.dot(self.inputs, self.W[\"data\"]) + self.b[\"data\"]\n",
    "#         return self.Y[\"data\"]\n",
    "    \n",
    "#     def backward_propogation(self, dy):\n",
    "#         si = dy.size\n",
    "#         self.W[\"delta\"] = dy.T.dot(self.inputs)\n",
    "#         self.b[\"delta\"] = np.sum(dy, axis=0) / si\n",
    "#         # self.Y[\"delta\"] = self.W[\"data\"].T.dot(dy)\n",
    "#         self.Y[\"delta\"] = np.dot(dy, self.W[\"delta\"]) / si\n",
    "\n",
    "#         self.W[\"data\"] -= self.W[\"delta\"].T * self.learning_rate\n",
    "#         self.b[\"data\"] -= self.b[\"delta\"] * self.learning_rate\n",
    "#         return self.Y[\"delta\"]\n",
    "\n",
    "class FC:\n",
    "    number = 0\n",
    "    def __init__ (self, num_in, num_out, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_in = num_in\n",
    "        self.num_out = num_out\n",
    "        self.W = {\"data\": np.random.randn(num_in, num_out) / np.sqrt(num_in/2), \"delta\":0}\n",
    "        self.b = {\"data\": np.random.normal(0.0, 0.5, (1, num_out)) , \"delta\": 0}\n",
    "\n",
    "        self.input = {\"data\":None, \"delta\":None}\n",
    "        self.output = {\"data\":None, \"delta\":None}\n",
    "        self.name = FC.number\n",
    "        FC.number += 1\n",
    "\n",
    "    def forward_propogation(self, input):\n",
    "        self.input[\"data\"] = input\n",
    "        self.output[\"data\"] = np.dot(self.input[\"data\"], self.W[\"data\"]) + self.b[\"data\"]\n",
    "        return self.output[\"data\"]\n",
    "\n",
    "    def backward_propogation(self, doutput):\n",
    "        self.output[\"delta\"] = doutput\n",
    "        self.input[\"delta\"] = np.dot(self.output[\"delta\"], self.W[\"data\"].T) \n",
    "        # if self.name <= 1:\n",
    "        #     self.output[\"delta\"] = np.multiply(self.output[\"delta\"], 1 - np.power(self.output[\"data\"], 2))\n",
    "        \n",
    "        self.W[\"delta\"] = np.dot(self.input[\"data\"].T, self.output[\"delta\"]) / doutput.shape[0]\n",
    "        self.b[\"delta\"] = np.sum(self.output[\"delta\"], keepdims=True, axis=0) / doutput.shape[0]\n",
    "        # print(self.name)\n",
    "        # print(\"Mean weight\")\n",
    "        # print(np.mean(self.W[\"data\"]))\n",
    "        # print(\"Mean weight delta\")\n",
    "        # print(np.mean(self.W[\"delta\"]))\n",
    "        # print(\"Mean bias\")\n",
    "        # print(np.mean(self.b[\"data\"]))\n",
    "        # print(\"Mean bias delta\")\n",
    "        # print(np.mean(self.b[\"delta\"]))\n",
    "        \n",
    "        \n",
    "        self.W[\"data\"] = self.W[\"data\"] - self.W[\"delta\"] * self.learning_rate\n",
    "        self.b[\"data\"] = self.b[\"data\"] - self.b[\"delta\"] * self.learning_rate\n",
    "\n",
    "        # self.W[\"delta\"] = 0\n",
    "        # self.b[\"delta\"] = 0\n",
    "        return self.input[\"delta\"]\n",
    "\n",
    "\n",
    "class Maxpool:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def forward_propogation(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        temp = np.full((inputs.shape[0], inputs.shape[1], inputs.shape[2] // self.factor, inputs.shape[3] // self.factor), -float('inf'), dtype=inputs.dtype)\n",
    "        np.maximum.at(temp, (np.arange(inputs.shape[0])[:, None, None, None], np.arange(inputs.shape[1])[:, None, None], np.arange(inputs.shape[2])[:, None] // self.factor, np.arange(inputs.shape[3]) // self.factor), inputs)\n",
    "        return temp\n",
    "\n",
    "    def backward_propogation(self, dy):\n",
    "        return np.repeat(np.repeat(dy, self.factor, axis=2), self.factor, axis=3)\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward_propogation(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        return np.maximum(inputs, 0)\n",
    "        # ret = inputs.copy()\n",
    "        # ret[ret < 0] = 0\n",
    "        # return ret\n",
    "        # return np.maximum(inputs, 0).reshape(inputs.shape)\n",
    "\n",
    "    def backward_propogation(self, dy):\n",
    "        dx = dy.copy()\n",
    "        dx[(self.inputs < 0).reshape(dy.shape)] = 0\n",
    "        return dx\n",
    "\n",
    "class softmax:\n",
    "    def __init__(self):\n",
    "        self.input = {\"data\":None, \"delta\":None}\n",
    "        self.output = {\"data\":None, \"delta\":None}\n",
    "\n",
    "    def forward_propogation(self, input):\n",
    "        self.input[\"data\"] = input \n",
    "        self.output[\"data\"] = np.exp(input - np.max(input)) / np.sum(np.exp(input - np.max(input)), axis=1, keepdims=True)\n",
    "        return self.output[\"data\"]\n",
    "\n",
    "    def backward_propogation(self, dy):\n",
    "        self.output[\"delta\"] = dy\n",
    "        self.input[\"delta\"] = self.output[\"data\"] - self.output[\"delta\"]\n",
    "        return self.input[\"delta\"]\n",
    "\n",
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward_propogation(self, inputs):\n",
    "        self.N, self.Cout, self.H, _ = inputs.shape\n",
    "        return inputs.reshape(inputs.shape[0], np.prod(inputs.shape[1:]))\n",
    "\n",
    "    def backward_propogation(self, dy):\n",
    "        return dy.reshape(self.N, self.Cout, self.H, self.H)\n",
    "\n",
    "class Batchnorm:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward_propogation(self, X):\n",
    "        if self.name == \"FC\":\n",
    "            self.gamma = np.ones((1, np.prod(X.shape[1:])))\n",
    "            self.beta = np.zeros((1, np.prod(X.shape[1:])))\n",
    "            self.n_X = X.shape[0]\n",
    "\n",
    "            self.X = X\n",
    "            self.N, self.nodes= X.shape\n",
    "\n",
    "            self.mu = np.mean(X, axis = 0, keepdims=True)\n",
    "            self.var = np.var(X, axis=0, keepdims=True)\n",
    "            self.X_norm = (X - self.mu.T) / np.sqrt(self.var)\n",
    "            self.out = self.gamma * self.X_norm + self.beta\n",
    "            \n",
    "            return self.out.reshape(X.shape)\n",
    "\n",
    "    def backward_propogation(self, dy):\n",
    "        if self.name == \"FC\":\n",
    "            X_mu = self.X - self.mu\n",
    "            var_inv = 1./np.sqrt(self.var + 1e-8)\n",
    "            dX_norm = dy * self.gamma\n",
    "\n",
    "            dvar = np.sum(dX_norm * X_mu, axis = 0) * -0.5 * (self.var + 1e-8) ** (-3/2)\n",
    "            dmu = np.sum(dX_norm * -var_inv, axis = 0) + dvar * 1/dy.shape[0] * np.sum(-2 * X_mu, axis=0)\n",
    "            dX = (dX_norm * var_inv) + (dmu / self.n_X) + (dvar * 2/self.n_X * X_mu)\n",
    "            dbeta = np.sum(dy,axis=0)\n",
    "            dgamma = dy.T.dot(self.X_norm.T)\n",
    "\n",
    "            \n",
    "            self.gamma = self.gamma - dgamma\n",
    "            self.beta = self.beta - dbeta\n",
    "            return dX\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(data_name, train_percentage):\n",
    "    data = Data(data_name)\n",
    "    data.prepare_data(train_percentage)\n",
    "    return data\n",
    "data_name, train_percentage = \"MNIST_dataset.csv\", 0.002\n",
    "data = importData(data_name, train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5:\n",
    "    def __init__(self):\n",
    "        self.layout = list()\n",
    "        k1, Cin1, Cout1, factor, k2, Cin2, Cout2, nodes1, nodes2, nodes3, nodes4, learning_rate = 5, 1, 6, 2, 5, 6, 16, 256, 520, 50, 10, 1\n",
    "        self.layout.append(Convolution2D(k1, Cin1, Cout1))\n",
    "        self.layout.append(ReLU())\n",
    "        self.layout.append(Maxpool(factor))\n",
    "        self.layout.append(Convolution2D(k2, Cin2, Cout2))\n",
    "        self.layout.append(ReLU())\n",
    "        self.layout.append(Maxpool(factor))\n",
    "        self.layout.append(Flatten())\n",
    "        self.layout.append(FC(nodes1, nodes2, learning_rate))\n",
    "        self.layout.append(ReLU())\n",
    "        self.layout.append(FC(nodes2, nodes3, learning_rate))\n",
    "        self.layout.append(ReLU())\n",
    "        self.layout.append(FC(nodes3, nodes4, learning_rate))\n",
    "        # self.layout.append(Batchnorm(\"FC\"))\n",
    "        self.layout.append(softmax())\n",
    "\n",
    "    def forward_feed(self, input):\n",
    "        for index, i in enumerate(self.layout):\n",
    "            input = i.forward_propogation(input)\n",
    "            # print(input.shape)\n",
    "            if (np.sum(np.isnan(input)) > 0):\n",
    "                print(index)\n",
    "                print(\"Fuck\")\n",
    "                break\n",
    "        self.prediction = input\n",
    "        \n",
    "    def backward_feed(self, actual):\n",
    "        self.actual = actual\n",
    "        for j in self.layout[::-1]:\n",
    "            actual = j.backward_propogation(actual)\n",
    "            # print(actual.shape)\n",
    "            if (np.sum(np.isnan(actual)) > 0):\n",
    "                print(j)\n",
    "                print(\"kcuF\")\n",
    "                break\n",
    "\n",
    "    def L_i_vectorized(self):\n",
    "        act = self.actual.T\n",
    "        pred = self.prediction.T\n",
    "        delta = 1.0\n",
    "        margins = np.maximum(0, pred - pred[act==1] + delta)\n",
    "        margins[act==1] = 0\n",
    "        loss_i = np.sum(margins)\n",
    "        return loss_i/self.prediction.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Convolution2D' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m actual \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39my_train_vector\n\u001b[0;32m      7\u001b[0m arc\u001b[39m.\u001b[39mforward_feed(\u001b[39minput\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m arc\u001b[39m.\u001b[39;49mbackward_feed(actual)\n",
      "Cell \u001b[1;32mIn [30], line 33\u001b[0m, in \u001b[0;36mLeNet5.backward_feed\u001b[1;34m(self, actual)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactual \u001b[39m=\u001b[39m actual\n\u001b[0;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[1;32m---> 33\u001b[0m     actual \u001b[39m=\u001b[39m j\u001b[39m.\u001b[39;49mbackward_propogation(actual)\n\u001b[0;32m     34\u001b[0m     \u001b[39m# print(actual.shape)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[39mif\u001b[39;00m (np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39misnan(actual)) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n",
      "Cell \u001b[1;32mIn [12], line 29\u001b[0m, in \u001b[0;36mConvolution2D.backward_propogation\u001b[1;34m(self, dy)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m+\u001b[39m dy\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m bKernel\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m] \u001b[39mand\u001b[39;00m j \u001b[39m+\u001b[39m dy\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m bKernel\u001b[39m.\u001b[39mshape[\u001b[39m4\u001b[39m]:\n\u001b[0;32m     28\u001b[0m             bKernel[:, :, :, i : (i \u001b[39m+\u001b[39m dy\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), j : (j \u001b[39m+\u001b[39m dy\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])] \u001b[39m=\u001b[39m dy[:, :, np\u001b[39m.\u001b[39mnewaxis, :, :]\n\u001b[1;32m---> 29\u001b[0m             temp \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs[:, np\u001b[39m.\u001b[39mnewaxis, :, :, :] \u001b[39m*\u001b[39m bKernel)\u001b[39m.\u001b[39msum((\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m))\n\u001b[0;32m     30\u001b[0m             o[:, :, i, j] \u001b[39m=\u001b[39m temp\n\u001b[0;32m     31\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW[\u001b[39m\"\u001b[39m\u001b[39mdelta\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m o\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Convolution2D' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": [
    "arc = LeNet5()\n",
    "input = data.x_train.reshape(data.x_train.shape[0], 1, int(np.sqrt(data.x_train.shape[1])), int(np.sqrt(data.x_train.shape[1])))\n",
    "\n",
    "for i in range(20):\n",
    "    # input = data.x_train\n",
    "    actual = data.y_train_vector\n",
    "    arc.forward_feed(input)\n",
    "    arc.backward_feed(actual)\n",
    "    # print(arc.L_i_vectorized())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 7, 9, 5, 9, 1, 5, 9, 8, 2, 5, 9, 6, 5, 5, 6, 7, 7, 1, 6, 2, 8,\n",
       "       2, 9, 9, 9, 1, 8, 9, 1, 8, 9, 1, 6, 1, 1, 7, 5, 2, 8, 6, 7, 6, 1,\n",
       "       1, 8, 9, 2, 2, 1, 5, 5, 6, 5, 5, 6, 5, 9, 6, 7, 3, 8, 2, 2, 5, 1,\n",
       "       5, 5, 5, 7, 2, 6, 8, 6, 6, 5, 5, 5, 1, 2, 1, 6, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(arc.layout[-1].output[\"data\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(data.y_train == np.argmax(arc.layout[-1].output[\"data\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(arc.layout[-1].out, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 784)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x230455f0d60>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaiElEQVR4nO3df2xV9f3H8dfl1xW0vV2p7e0dpSugMAVqxqQ2SIejoe0Sw68/QF0EQ3CwYgbMaVhUZFvSDRM0mg72xwYjEWUmAtF8h8Fi26+uZaFCCNnW0KYTCG2ZJNxbipRKP98/+HrnhRa8l3v77r08H8lJ6L3n9L49nvnc4d5+6nHOOQEAMMiGWQ8AALg9ESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGBihPUA1+rr69OZM2eUlpYmj8djPQ4AIErOOXV1dSkQCGjYsIHvc4ZcgM6cOaO8vDzrMQAAt+jUqVMaN27cgM8PuQClpaVJkh7WjzRCI42nAQBE60v16mP9T/i/5wNJWICqq6v1yiuvqKOjQ4WFhXrjjTc0c+bMmx731V+7jdBIjfAQIABIOv+/wujN3kZJyIcQdu/erfXr12vjxo369NNPVVhYqLKyMp09ezYRLwcASEIJCdCWLVu0cuVKPfXUU7rvvvu0bds2jRkzRn/6058S8XIAgCQU9wBdvnxZTU1NKi0t/e+LDBum0tJSNTQ0XLd/T0+PQqFQxAYASH1xD9Dnn3+uK1euKCcnJ+LxnJwcdXR0XLd/VVWVfD5feOMTcABwezD/QdQNGzYoGAyGt1OnTlmPBAAYBHH/FFxWVpaGDx+uzs7OiMc7Ozvl9/uv29/r9crr9cZ7DADAEBf3O6BRo0ZpxowZqqmpCT/W19enmpoaFRcXx/vlAABJKiE/B7R+/XotW7ZM3//+9zVz5ky99tpr6u7u1lNPPZWIlwMAJKGEBGjJkiX6z3/+o5deekkdHR164IEHtH///us+mAAAuH15nHPOeoivC4VC8vl8mqP5rIQAAEnoS9erWu1TMBhUenr6gPuZfwoOAHB7IkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACZGWA8AJMLFhUUxHVfw3D+jPmZnfn1MrzWUTdy9KupjJq1rTMAkSGXcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJliMFENeTkN61MfszP9DAia5fbQu2Rb1MU8+VBL1MZ3FoaiPQergDggAYIIAAQBMxD1AL7/8sjweT8Q2ZcqUeL8MACDJJeQ9oPvvv18ffvjhf19kBG81AQAiJaQMI0aMkN/vT8S3BgCkiIS8B3TixAkFAgFNmDBBTzzxhE6ePDngvj09PQqFQhEbACD1xT1ARUVF2rFjh/bv36+tW7eqra1Ns2fPVldXV7/7V1VVyefzhbe8vLx4jwQAGII8zjmXyBc4f/688vPztWXLFq1YseK653t6etTT0xP+OhQKKS8vT3M0XyM8IxM5GpJEbD8HVJ+ASXAjT37GzwHhqi9dr2q1T8FgUOnpA//vN+GfDsjIyNC9996rlpaWfp/3er3yer2JHgMAMMQk/OeALly4oNbWVuXm5ib6pQAASSTuAXr22WdVV1enf//73/rb3/6mhQsXavjw4Xrsscfi/VIAgCQW97+CO336tB577DGdO3dOd999tx5++GE1Njbq7rvvjvdLAQCSWNwD9Pbbb8f7W2KI4sMB+LpY/t3OXviTqI8Zs+dQ1MdgaGItOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARMJ/IR0G18WFRVEf87/Vf0jAJLiRibtXDcrrtC7ZNiivE6tYrr2yPQ/EfxCY4A4IAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJlgNO8WcKfFYjzAkPPlZSUzHfdJ4X9THTFrXGP0xiv6YWMyu/0lMxw3lFdJbXn0o6mNi+XeExOMOCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwWKkGPIm7l4V9TGxLj45WIuEDpYxew7FdmB1fOcA+sMdEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggsVIU0wsi3BOVPSLfcYqlvlSbYHQwXRxYVGMRx6N5xhAv7gDAgCYIEAAABNRB6i+vl6PPvqoAoGAPB6P9u7dG/G8c04vvfSScnNzNXr0aJWWlurEiRPxmhcAkCKiDlB3d7cKCwtVXd3/b6zavHmzXn/9dW3btk2HDh3SnXfeqbKyMl26dOmWhwUApI6oP4RQUVGhioqKfp9zzum1117TCy+8oPnz50uSdu7cqZycHO3du1dLly69tWkBACkjru8BtbW1qaOjQ6WlpeHHfD6fioqK1NDQ0O8xPT09CoVCERsAIPXFNUAdHR2SpJycnIjHc3Jyws9dq6qqSj6fL7zl5eXFcyQAwBBl/im4DRs2KBgMhrdTp05ZjwQAGARxDZDf75ckdXZ2Rjze2dkZfu5aXq9X6enpERsAIPXFNUAFBQXy+/2qqakJPxYKhXTo0CEVFxfH86UAAEku6k/BXbhwQS0tLeGv29radPToUWVmZmr8+PFau3atfvOb3+iee+5RQUGBXnzxRQUCAS1YsCCecwMAklzUATp8+LAeeeSR8Nfr16+XJC1btkw7duzQc889p+7ubj399NM6f/68Hn74Ye3fv1933HFH/KYGACQ9j3POWQ/xdaFQSD6fT3M0XyM8I63HAZJaTkNs76nuzK+P8yTxM7vyJ1EfM2bPoQRMgoF86XpVq30KBoM3fF/f/FNwAIDbEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAExE/esYACSPobyqtSQ9+VlJ1MewsnXq4A4IAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBYqRAkshpSLceIe46i0PWI8AQd0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkWIwUMtLz6UNTHfJC/LQGTxM+Tn5XEcBSLkd7OuAMCAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEywGClwi2JZWLR1SeotLNpZzMKiiA53QAAAEwQIAGAi6gDV19fr0UcfVSAQkMfj0d69eyOeX758uTweT8RWXl4er3kBACki6gB1d3ersLBQ1dXVA+5TXl6u9vb28PbWW2/d0pAAgNQT9YcQKioqVFFRccN9vF6v/H5/zEMBAFJfQt4Dqq2tVXZ2tiZPnqzVq1fr3LlzA+7b09OjUCgUsQEAUl/cA1ReXq6dO3eqpqZGv/vd71RXV6eKigpduXKl3/2rqqrk8/nCW15eXrxHAgAMQXH/OaClS5eG/zxt2jRNnz5dEydOVG1trebOnXvd/hs2bND69evDX4dCISIEALeBhH8Me8KECcrKylJLS0u/z3u9XqWnp0dsAIDUl/AAnT59WufOnVNubm6iXwoAkESi/iu4CxcuRNzNtLW16ejRo8rMzFRmZqY2bdqkxYsXy+/3q7W1Vc8995wmTZqksrKyuA4OAEhuUQfo8OHDeuSRR8Jff/X+zbJly7R161YdO3ZMf/7zn3X+/HkFAgHNmzdPv/71r+X1euM3NQAg6UUdoDlz5sg5N+DzH3zwwS0NBFhKxYVFY9G2+btRHzNGhxIwCVIZa8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADARNx/JTcwFOQ0xPabdT/IT62VrWdX/iSm48bsYWVrJB53QAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACRYjxZAXy8KiO/PrEzBJ8vnf6j/EdNyTz5VEfcwnjffF9FpDWaDeRX0MC7l+c9wBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmWIwUg4qFRZNDTOc8Ff89LYn+kIklq6I+ZtK6xuhfKAVwBwQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmGAxUsSMhUUB3ArugAAAJggQAMBEVAGqqqrSgw8+qLS0NGVnZ2vBggVqbm6O2OfSpUuqrKzU2LFjddddd2nx4sXq7OyM69AAgOQXVYDq6upUWVmpxsZGHThwQL29vZo3b566u7vD+6xbt07vvfee3nnnHdXV1enMmTNatGhR3AcHACS3qD6EsH///oivd+zYoezsbDU1NamkpETBYFB//OMftWvXLv3whz+UJG3fvl3f/e531djYqIceeih+kwMAktotvQcUDAYlSZmZmZKkpqYm9fb2qrS0NLzPlClTNH78eDU0NPT7PXp6ehQKhSI2AEDqizlAfX19Wrt2rWbNmqWpU6dKkjo6OjRq1ChlZGRE7JuTk6OOjo5+v09VVZV8Pl94y8vLi3UkAEASiTlAlZWVOn78uN5+++1bGmDDhg0KBoPh7dSpU7f0/QAAySGmH0Rds2aN3n//fdXX12vcuHHhx/1+vy5fvqzz589H3AV1dnbK7/f3+728Xq+8Xm8sYwAAklhUd0DOOa1Zs0Z79uzRwYMHVVBQEPH8jBkzNHLkSNXU1IQfa25u1smTJ1VcXByfiQEAKSGqO6DKykrt2rVL+/btU1paWvh9HZ/Pp9GjR8vn82nFihVav369MjMzlZ6ermeeeUbFxcV8Ag4AECGqAG3dulWSNGfOnIjHt2/fruXLl0uSXn31VQ0bNkyLFy9WT0+PysrK9Pvf/z4uwwIAUkdUAXLO3XSfO+64Q9XV1aquro55KAyuWBYVlVhYNBlM3L3KeoS4m/XQP6I+hmt1aGItOACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJiI6TeiIrWwUvCtGawVpyeta4z+GEV/zFDXGcMxZXog3mMMKBXPeaJwBwQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmGAxUsS8mGbrkm1xnqR/scwXy8KdsWLxSSA23AEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACY8zjlnPcTXhUIh+Xw+zdF8jfCMtB4HABClL12varVPwWBQ6enpA+7HHRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwEVWAqqqq9OCDDyotLU3Z2dlasGCBmpubI/aZM2eOPB5PxLZq1aq4Dg0ASH5RBaiurk6VlZVqbGzUgQMH1Nvbq3nz5qm7uztiv5UrV6q9vT28bd68Oa5DAwCS34hodt6/f3/E1zt27FB2draamppUUlISfnzMmDHy+/3xmRAAkJJu6T2gYDAoScrMzIx4/M0331RWVpamTp2qDRs26OLFiwN+j56eHoVCoYgNAJD6oroD+rq+vj6tXbtWs2bN0tSpU8OPP/7448rPz1cgENCxY8f0/PPPq7m5We+++26/36eqqkqbNm2KdQwAQJLyOOdcLAeuXr1af/3rX/Xxxx9r3LhxA+538OBBzZ07Vy0tLZo4ceJ1z/f09Kinpyf8dSgUUl5enuZovkZ4RsYyGgDA0JeuV7Xap2AwqPT09AH3i+kOaM2aNXr//fdVX19/w/hIUlFRkSQNGCCv1yuv1xvLGACAJBZVgJxzeuaZZ7Rnzx7V1taqoKDgpsccPXpUkpSbmxvTgACA1BRVgCorK7Vr1y7t27dPaWlp6ujokCT5fD6NHj1ara2t2rVrl370ox9p7NixOnbsmNatW6eSkhJNnz49If8AAIDkFNV7QB6Pp9/Ht2/fruXLl+vUqVP68Y9/rOPHj6u7u1t5eXlauHChXnjhhRv+PeDXhUIh+Xw+3gMCgCSVkPeAbtaqvLw81dXVRfMtAQC3KdaCAwCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGE9wLWcc5KkL9UrOeNhAABR+1K9kv773/OBDLkAdXV1SZI+1v8YTwIAuBVdXV3y+XwDPu9xN0vUIOvr69OZM2eUlpYmj8cT8VwoFFJeXp5OnTql9PR0owntcR6u4jxcxXm4ivNw1VA4D845dXV1KRAIaNiwgd/pGXJ3QMOGDdO4ceNuuE96evptfYF9hfNwFefhKs7DVZyHq6zPw43ufL7ChxAAACYIEADARFIFyOv1auPGjfJ6vdajmOI8XMV5uIrzcBXn4apkOg9D7kMIAIDbQ1LdAQEAUgcBAgCYIEAAABMECABgImkCVF1dre985zu64447VFRUpL///e/WIw26l19+WR6PJ2KbMmWK9VgJV19fr0cffVSBQEAej0d79+6NeN45p5deekm5ubkaPXq0SktLdeLECZthE+hm52H58uXXXR/l5eU2wyZIVVWVHnzwQaWlpSk7O1sLFixQc3NzxD6XLl1SZWWlxo4dq7vuukuLFy9WZ2en0cSJ8U3Ow5w5c667HlatWmU0cf+SIkC7d+/W+vXrtXHjRn366acqLCxUWVmZzp49az3aoLv//vvV3t4e3j7++GPrkRKuu7tbhYWFqq6u7vf5zZs36/XXX9e2bdt06NAh3XnnnSorK9OlS5cGedLEutl5kKTy8vKI6+Ott94axAkTr66uTpWVlWpsbNSBAwfU29urefPmqbu7O7zPunXr9N577+mdd95RXV2dzpw5o0WLFhlOHX/f5DxI0sqVKyOuh82bNxtNPACXBGbOnOkqKyvDX1+5csUFAgFXVVVlONXg27hxoyssLLQew5Qkt2fPnvDXfX19zu/3u1deeSX82Pnz553X63VvvfWWwYSD49rz4Jxzy5Ytc/PnzzeZx8rZs2edJFdXV+ecu/rvfuTIke6dd94J7/PPf/7TSXINDQ1WYybctefBOed+8IMfuJ/97Gd2Q30DQ/4O6PLly2pqalJpaWn4sWHDhqm0tFQNDQ2Gk9k4ceKEAoGAJkyYoCeeeEInT560HslUW1ubOjo6Iq4Pn8+noqKi2/L6qK2tVXZ2tiZPnqzVq1fr3Llz1iMlVDAYlCRlZmZKkpqamtTb2xtxPUyZMkXjx49P6evh2vPwlTfffFNZWVmaOnWqNmzYoIsXL1qMN6AhtxjptT7//HNduXJFOTk5EY/n5OToX//6l9FUNoqKirRjxw5NnjxZ7e3t2rRpk2bPnq3jx48rLS3NejwTHR0dktTv9fHVc7eL8vJyLVq0SAUFBWptbdUvf/lLVVRUqKGhQcOHD7ceL+76+vq0du1azZo1S1OnTpV09XoYNWqUMjIyIvZN5euhv/MgSY8//rjy8/MVCAR07NgxPf/882pubta7775rOG2kIR8g/FdFRUX4z9OnT1dRUZHy8/P1l7/8RStWrDCcDEPB0qVLw3+eNm2apk+frokTJ6q2tlZz5841nCwxKisrdfz48dvifdAbGeg8PP300+E/T5s2Tbm5uZo7d65aW1s1ceLEwR6zX0P+r+CysrI0fPjw6z7F0tnZKb/fbzTV0JCRkaF7771XLS0t1qOY+eoa4Pq43oQJE5SVlZWS18eaNWv0/vvv66OPPor49S1+v1+XL1/W+fPnI/ZP1ethoPPQn6KiIkkaUtfDkA/QqFGjNGPGDNXU1IQf6+vrU01NjYqLiw0ns3fhwgW1trYqNzfXehQzBQUF8vv9EddHKBTSoUOHbvvr4/Tp0zp37lxKXR/OOa1Zs0Z79uzRwYMHVVBQEPH8jBkzNHLkyIjrobm5WSdPnkyp6+Fm56E/R48elaShdT1Yfwrim3j77bed1+t1O3bscP/4xz/c008/7TIyMlxHR4f1aIPq5z//uautrXVtbW3uk08+caWlpS4rK8udPXvWerSE6urqckeOHHFHjhxxktyWLVvckSNH3Geffeacc+63v/2ty8jIcPv27XPHjh1z8+fPdwUFBe6LL74wnjy+bnQeurq63LPPPusaGhpcW1ub+/DDD933vvc9d88997hLly5Zjx43q1evdj6fz9XW1rr29vbwdvHixfA+q1atcuPHj3cHDx50hw8fdsXFxa64uNhw6vi72XloaWlxv/rVr9zhw4ddW1ub27dvn5swYYIrKSkxnjxSUgTIOefeeOMNN378eDdq1Cg3c+ZM19jYaD3SoFuyZInLzc11o0aNct/+9rfdkiVLXEtLi/VYCffRRx85Sddty5Ytc85d/Sj2iy++6HJycpzX63Vz5851zc3NtkMnwI3Ow8WLF928efPc3Xff7UaOHOny8/PdypUrU+7/pPX3zy/Jbd++PbzPF1984X7605+6b33rW27MmDFu4cKFrr293W7oBLjZeTh58qQrKSlxmZmZzuv1ukmTJrlf/OIXLhgM2g5+DX4dAwDAxJB/DwgAkJoIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABP/B9kJd/Evo86UAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data.x_train[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2302e5cda80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(arc.layout[0].output[1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07581514, -0.01788062, -0.12350075,  0.03754671,  0.0169905 ],\n",
       "       [-0.17040323, -0.14420417,  0.09091042, -0.00761174, -0.05232261],\n",
       "       [ 0.29533529,  0.78976551,  1.50955162,  2.4197696 ,  0.0780152 ],\n",
       "       [ 0.49497989,  1.61996955,  4.11461879,  6.68472197,  0.04017892],\n",
       "       [-0.10112273, -0.04446973,  0.12539909,  0.00696695, -0.08097848]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc.layout[0].W[\"data\"][0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x210173a77f0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(arc.layout[0].W[\"data\"][0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = data.x_train.reshape(data.x_train.shape[0], 1, int(np.sqrt(data.x_train.shape[1])), int(np.sqrt(data.x_train.shape[1])))\n",
    "kernel_size, Cin, Cout, factor = 5, 1, 6, 2\n",
    "conv1 = Convolution2D(kernel_size, Cin, Cout)\n",
    "relu1 = ReLU()\n",
    "max1 = Maxpool(factor)\n",
    "kernel_size, Cin, Cout = 5, 6, 16\n",
    "conv2 = Convolution2D(kernel_size, Cin, Cout)\n",
    "max2 = Maxpool(factor)\n",
    "relu2 = ReLU()\n",
    "flat = Flatten()\n",
    "n_nodes, n_output, learning_rate = 256, 80, 0.1\n",
    "fc1 = FC(n_nodes, n_output, learning_rate)\n",
    "relu3 = ReLU()\n",
    "n_nodes, n_output, learning_rate = 80, 10, 0.1\n",
    "fc2 = FC(n_nodes, n_output, learning_rate)\n",
    "soft = softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = conv1.forward_propogation(input)\n",
    "r1 = relu1.forward_propogation(c1)\n",
    "m1 = max1.forward_propogation(r1)\n",
    "c2 = conv2.forward_propogation(m1)\n",
    "r2 = relu2.forward_propogation(c2)\n",
    "m2 = max2.forward_propogation(r2)\n",
    "flt = flat.forward_propogation(m2)\n",
    "f1 = fc1.forward_propogation(flt)\n",
    "r3 = relu3.forward_propogation(f1)\n",
    "f2 = fc2.forward_propogation(r3.T)\n",
    "sft = soft.forward_propogation(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 80)\n",
      "(84, 16, 8, 8)\n",
      "(84, 6, 24, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(84, 1, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = data.y_train_vector\n",
    "sft_b = soft.backward_propogation(actual.T)\n",
    "f2_b = fc2.backward_propogation(sft_b)\n",
    "r3_b = relu3.backward_propogation(f2_b)\n",
    "f1_b = fc1.backward_propogation(r3_b.T)\n",
    "flt_b = flat.backward_propogation(f1_b)\n",
    "m2_b = max2.backward_propogation(flt_b)\n",
    "r2_b = relu2.backward_propogation(m2_b)\n",
    "c2_b = conv2.backward_propogation(r2_b)\n",
    "m1_b = max1.backward_propogation(c2_b)\n",
    "r1_b = relu1.backward_propogation(m1_b)\n",
    "c1_b = conv1.backward_propogation(r1_b)\n",
    "c1_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1, 5, 5)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1.W[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b414857ca0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(conv2.output[4, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(np.isnan(f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 16, 4, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13c2cffef50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(m1[2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_0 = 5\n",
    "Cin_0 = 1\n",
    "Cout_0 = 6\n",
    "Stride_0 = 1\n",
    "Padding_0 = 0\n",
    "W_0 = np.random.normal(0.0, np.sqrt(2/Cin_0), (Cout_0, Cin_0, F_0, F_0))\n",
    "image = data.x_train[0:1, :]\n",
    "N, H_0 = image.shape\n",
    "H_0 = int(np.sqrt(H_0))\n",
    "image = image.reshape((N, Cin_0, H_0, H_0))\n",
    "nex_height = int((H_0 - F_0 + 2 * Padding_0)/ Stride_0) + 1 \n",
    "Z_0 = np.zeros((N, Cout_0, nex_height, nex_height))\n",
    "for i in range(Z_0.shape[2]):\n",
    "    for j in range(Z_0.shape[3]):\n",
    "        bKernel = np.zeros((N, Cout_0, Cin_0, H_0, H_0))\n",
    "        if i + F_0 <= bKernel.shape[3] and j + F_0 <= bKernel.shape[4]:\n",
    "            bKernel[:, :, :, i : (i + F_0), j : (j + F_0)] = W_0\n",
    "            temp = (image[:, np.newaxis, :, :, :] * bKernel).sum((3, 4))\n",
    "            Z_0[:, :, i, j] = temp.reshape(temp.shape[0], temp.shape[1])\n",
    "print(Z_0.shape)\n",
    "Z_0 = np.maximum(0, Z_0)\n",
    "print(Z_0.shape)\n",
    "Factor_0 = 2\n",
    "temp = np.full((Z_0.shape[0], Z_0.shape[1], Z_0.shape[2] // Factor_0, Z_0.shape[3] // Factor_0), -float('inf'), dtype=Z_0.dtype)\n",
    "np.maximum.at(temp, (np.arange(Z_0.shape[0])[:, None, None, None], np.arange(Z_0.shape[1])[:, None, None], np.arange(Z_0.shape[2])[:, None] // Factor_0, np.arange(Z_0.shape[3]) // Factor_0), Z_0)\n",
    "\n",
    "F_1 = 5\n",
    "Cin_1 = 6\n",
    "Cout_1 = 16\n",
    "Stride_1 = 1\n",
    "Padding_1 = 0\n",
    "W_1 = np.random.normal(0.0, np.sqrt(2/Cin_1), (Cout_1, Cin_1, F_1, F_1))\n",
    "image = temp\n",
    "N, Cin_1, H_1, _ = image.shape\n",
    "nex_height = int((H_1 - F_1 + 2 * Padding_1)/ Stride_1) + 1 \n",
    "Z_1 = np.zeros((N, Cout_1, nex_height, nex_height))\n",
    "for i in range(Z_1.shape[2]):\n",
    "    for j in range(Z_1.shape[3]):\n",
    "        bKernel = np.zeros((N, Cout_1, Cin_1, H_1, H_1))\n",
    "        if i + F_1 <= bKernel.shape[3] and j + F_1 <= bKernel.shape[4]:\n",
    "            bKernel[:, :, :, i : (i + F_1), j : (j + F_1)] = W_1\n",
    "            temp = (image[:, np.newaxis, :, :, :] * bKernel).sum((2, 3, 4))\n",
    "            Z_1[:, :, i, j] = temp.reshape(temp.shape[0], temp.shape[1])\n",
    "print(Z_1.shape)\n",
    "Z_1 = np.maximum(0, Z_1)\n",
    "print(Z_1.shape)\n",
    "Factor_1 = 2\n",
    "temp_0 = np.full((Z_1.shape[0], Z_1.shape[1], Z_1.shape[2] // Factor_1, Z_1.shape[3] // Factor_1), -float('inf'), dtype=Z_1.dtype)\n",
    "np.maximum.at(temp_0, (np.arange(Z_1.shape[0])[:, None, None, None], np.arange(Z_1.shape[1])[:, None, None], np.arange(Z_1.shape[2])[:, None] // Factor_1, np.arange(Z_1.shape[3]) // Factor_1), Z_1)\n",
    "print(temp_0.shape)\n",
    "input = temp_0.reshape(-1)\n",
    "input = input.reshape(1, input.shape[0])\n",
    "print(input.shape[0])\n",
    "net = DenseNetwork(3, [input.shape[1], 100, 10])\n",
    "net.initialize_weights()\n",
    "net.initialize_layers(input)\n",
    "net.link_layers()\n",
    "net.forward_feed()\n",
    "out = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]).reshape(10, 1)\n",
    "net.backward_feed(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    class Bias:\n",
    "        def __init__(self, n_nodes):\n",
    "            self.data = np.random.normal(loc = 0.0, scale = 0.5, size = (n_nodes, 1)) / np.sqrt(n_nodes)\n",
    "            self.delta = np.zeros((1))\n",
    "            \n",
    "        def update_data(self, alpha):\n",
    "            self.data = self.data - alpha * self.delta\n",
    "            if self.isNaN() > 0:\n",
    "                print(\"Nan occured in updated bias\")\n",
    "                exit()\n",
    "            self.reset_delta()\n",
    "            \n",
    "        def reset_delta(self):\n",
    "#             m,  = self.delta.shape\n",
    "            self.delta = np.zeros((1))\n",
    "            \n",
    "        def isNaN(self):\n",
    "            return np.sum(np.isnan(self.data))\n",
    "            \n",
    "        def __str__(self):\n",
    "            return f\"Bias Data :{self.data}, \\n Bias Delta: {self.delta}\"\n",
    "        \n",
    "    def __init__(self, n_nodes, activation_function, input_weight=None, output_weight=None):\n",
    "        self.bias = self.Bias(n_nodes)\n",
    "        self.input_weight = input_weight\n",
    "        self.output_weight = output_weight\n",
    "        if activation_function == \"softmax\":\n",
    "            self.activate_layer = self.activate_softmax\n",
    "            self.deactivate_layer = self.deactivate_softmax\n",
    "        else:\n",
    "            self.activate_layer = self.activate_ReLU\n",
    "            self.deactivate_layer = lambda actual : self.deactivate_ReLU(actual)\n",
    "            \n",
    "    def deactivate_softmax(self, actual):\n",
    "        self.dZ = self.A - actual\n",
    "        \n",
    "    def deactivate_ReLU(self):\n",
    "        self.dZ = self.output_weight.data.T.dot(self.output_layer.dZ) * Layer.deriv_ReLU(self.Z)\n",
    "        \n",
    "    def activate_softmax(self):\n",
    "        self.A = Layer.softmax(self.Z)\n",
    "        \n",
    "    def activate_ReLU(self):\n",
    "        self.A = Layer.ReLU(self.Z)\n",
    "        \n",
    "    def softmax(Z):\n",
    "#         expZ = np.exp(Z - np.max(Z))\n",
    "#         return expZ / np.sum(expZ, 0)\n",
    "        return np.exp(Z)/np.sum(np.exp(Z), 0)\n",
    "\n",
    "    def deriv_ReLU(Z):\n",
    "        return Z > 0\n",
    "    \n",
    "    def ReLU(Z):\n",
    "        return np.maximum(Z, 0)\n",
    "        \n",
    "    def set_input_layer(self, input_layer):\n",
    "        if hasattr(self, 'input_weight'):\n",
    "            self.input_layer = input_layer\n",
    "    \n",
    "    def set_output_layer(self, output_layer):\n",
    "        if hasattr(self, 'output_weight'):\n",
    "            self.output_layer = output_layer\n",
    "\n",
    "    def forward_propogation(self):\n",
    "        if hasattr(self, 'input_layer'):\n",
    "            self.Z = self.input_weight.data.dot(self.input_layer.A) + self.bias.data\n",
    "            self.activate_layer()\n",
    "            \n",
    "    def backward_propogation(self, actual):\n",
    "        si = actual.size\n",
    "        # if hasattr(self, 'input_layer'):\n",
    "        if hasattr(self, 'output_layer'):\n",
    "            self.deactivate_ReLU()\n",
    "        else:\n",
    "            self.deactivate_softmax(actual)\n",
    "        self.input_weight.delta = self.dZ.dot(self.input_layer.A.T) / si\n",
    "        self.bias.delta = np.sum(self.dZ) / si\n",
    "            \n",
    "    def update_parameters(self, alpha):\n",
    "        if hasattr(self, 'input_layer'):\n",
    "            self.input_weight.update_data(alpha)\n",
    "            self.bias.update_data(alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetwork:\n",
    "    def __init__(self, n_layers, n_nodes_list):\n",
    "        self.n_hidden = n_layers - 2\n",
    "        self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DenseNetwork:\n",
    "    class Weight:\n",
    "        def __init__(self, n_input, n_output):\n",
    "            self.data = np.random.randn(n_output, n_input) / np.sqrt(n_input/2)\n",
    "            # self.data = np.random.normal(loc = 0.0, scale = 0.5, size = (n_output, n_input)) / np.sqrt(n_input/2)\n",
    "            self.delta = np.zeros((n_output, n_input))\n",
    "            \n",
    "        def reset_delta(self):\n",
    "            m, n = self.delta.shape\n",
    "            self.delta = np.zeros((m, n))\n",
    "\n",
    "        def update_data(self, alpha):\n",
    "            self.data = self.data - alpha * self.delta\n",
    "            if self.isNaN() > 0:\n",
    "                print(\"Nan occured in updated weight\")\n",
    "                exit()\n",
    "            self.reset_delta()\n",
    "        \n",
    "        def isNaN(self):\n",
    "            return np.sum(np.isnan(self.data))\n",
    "        \n",
    "        def __str__(self):\n",
    "            return f\"Weight Data :{self.data}, \\n Weight Delta: {self.delta}\"\n",
    "        \n",
    "    def __init__(self, n_layers, n_nodes_list):\n",
    "        self.n_hidden = n_layers - 2\n",
    "        self.weights_list = list()\n",
    "        self.layers_list = list()\n",
    "        self.n_nodes_list = n_nodes_list\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        for i in range(self.n_hidden + 1):\n",
    "            cur_nodes = self.n_nodes_list[i]\n",
    "            nex_nodes = self.n_nodes_list[i + 1]\n",
    "            self.weights_list.append(self.Weight(cur_nodes, nex_nodes))\n",
    "            \n",
    "    def initialize_layers(self, data):\n",
    "        self.layers_list.append(Input_Layer(data, self.weights_list[0]))\n",
    "        for j in range(1, 1 + self.n_hidden):\n",
    "            self.layers_list.append(Layer(self.n_nodes_list[j], \"ReLU\", input_weight = self.weights_list[j - 1], output_weight = self.weights_list[j]))\n",
    "        self.layers_list.append(Layer(self.n_nodes_list[-1], \"softmax\", input_weight = self.weights_list[-1]))\n",
    "        \n",
    "    def link_layers(self):\n",
    "        self.layers_list[0].set_output_layer(self.layers_list[1])\n",
    "        for k in range(1, 1 + self.n_hidden):\n",
    "            self.layers_list[k].set_input_layer(self.layers_list[k -1])\n",
    "            self.layers_list[k].set_output_layer(self.layers_list[k + 1])\n",
    "        self.layers_list[-1].set_input_layer(self.layers_list[-2])\n",
    "        \n",
    "    def forward_feed(self):\n",
    "        for b in self.layers_list:\n",
    "            b.forward_propogation()\n",
    "            \n",
    "    def backward_feed(self, actual):\n",
    "        for c in self.layers_list[::-1]:\n",
    "            c.backward_propogation(actual)\n",
    "            \n",
    "    def update_network(self, alpha):\n",
    "        for d in self.layers_list:\n",
    "            d.update_parameters(alpha)\n",
    "\n",
    "    def accuracy(act, pred):\n",
    "        res = sum(argmax(pred, axis=0) == argmax(act, axis=0)) / pred.shape[1]\n",
    "        return res\n",
    "        \n",
    "            \n",
    "    def mean_squared_error(act, pred):\n",
    "        diff = pred - act\n",
    "        differences_squared = diff ** 2\n",
    "        mean_diff = differences_squared.mean()\n",
    "        return mean_diff\n",
    "    \n",
    "    def L_i_vectorized(act, pred):\n",
    "        delta = 1.0\n",
    "        margins = np.maximum(0, pred - pred[act==1] + delta)\n",
    "        margins[act==1] = 0\n",
    "        loss_i = np.sum(margins)\n",
    "        return loss_i/pred.shape[1]\n",
    "\n",
    "    def printStatement(self, act, iteration, epoch):\n",
    "        output = self.layers_list[-1].A\n",
    "        statement = \"Loss :\" + str(DenseNetwork.L_i_vectorized(act, output)) + \"; MSE: \" + str(DenseNetwork.mean_squared_error(act, output)) + \"; Accuracy: \" + str(DenseNetwork.accuracy(act, output)) + \" \" + str(iteration) + \" / \" + str(epoch)\n",
    "        return statement\n",
    "\n",
    "    def prediction(self, test_image):\n",
    "        temp = self.layers_list[0].A\n",
    "        self.layers_list[0].A = test_image\n",
    "        self.forward_feed()\n",
    "        output = argmax(self.layers_list[-1].A, axis=0)\n",
    "        self.layers_list[0].A = temp\n",
    "        print(\"I predict it as \" + str(output))\n",
    "\n",
    "class Layer:\n",
    "    class Bias:\n",
    "        def __init__(self, n_nodes):\n",
    "            self.data = np.random.normal(loc = 0.0, scale = 0.5, size = (n_nodes, 1)) / np.sqrt(n_nodes)\n",
    "            self.delta = np.zeros((1))\n",
    "            \n",
    "        def update_data(self, alpha):\n",
    "            self.data = self.data - alpha * self.delta\n",
    "            if self.isNaN() > 0:\n",
    "                print(\"Nan occured in updated bias\")\n",
    "                exit()\n",
    "            self.reset_delta()\n",
    "            \n",
    "        def reset_delta(self):\n",
    "#             m,  = self.delta.shape\n",
    "            self.delta = np.zeros((1))\n",
    "            \n",
    "        def isNaN(self):\n",
    "            return np.sum(np.isnan(self.data))\n",
    "            \n",
    "        def __str__(self):\n",
    "            return f\"Bias Data :{self.data}, \\n Bias Delta: {self.delta}\"\n",
    "        \n",
    "    def __init__(self, n_nodes, activation_function, input_weight=None, output_weight=None):\n",
    "        self.bias = self.Bias(n_nodes)\n",
    "        self.input_weight = input_weight\n",
    "        self.output_weight = output_weight\n",
    "        if activation_function == \"softmax\":\n",
    "            self.activate_layer = self.activate_softmax\n",
    "            self.deactivate_layer = self.deactivate_softmax\n",
    "        else:\n",
    "            self.activate_layer = self.activate_ReLU\n",
    "            self.deactivate_layer = lambda actual : self.deactivate_ReLU(actual)\n",
    "            \n",
    "    def deactivate_softmax(self, actual):\n",
    "        self.dZ = self.A - actual\n",
    "        \n",
    "    def deactivate_ReLU(self):\n",
    "        self.dZ = self.output_weight.data.T.dot(self.output_layer.dZ) * Layer.deriv_ReLU(self.Z)\n",
    "        \n",
    "    def activate_softmax(self):\n",
    "        self.A = Layer.softmax(self.Z)\n",
    "        \n",
    "    def activate_ReLU(self):\n",
    "        self.A = Layer.ReLU(self.Z)\n",
    "        \n",
    "    def softmax(Z):\n",
    "#         expZ = np.exp(Z - np.max(Z))\n",
    "#         return expZ / np.sum(expZ, 0)\n",
    "        return np.exp(Z)/np.sum(np.exp(Z), 0)\n",
    "\n",
    "    def deriv_ReLU(Z):\n",
    "        return Z > 0\n",
    "    \n",
    "    def ReLU(Z):\n",
    "        return np.maximum(Z, 0)\n",
    "        \n",
    "    def set_input_layer(self, input_layer):\n",
    "        if hasattr(self, 'input_weight'):\n",
    "            self.input_layer = input_layer\n",
    "    \n",
    "    def set_output_layer(self, output_layer):\n",
    "        if hasattr(self, 'output_weight'):\n",
    "            self.output_layer = output_layer\n",
    "\n",
    "    def forward_propogation(self):\n",
    "        if hasattr(self, 'input_layer'):\n",
    "            self.Z = self.input_weight.data.dot(self.input_layer.A) + self.bias.data\n",
    "            self.activate_layer()\n",
    "            \n",
    "    def backward_propogation(self, actual):\n",
    "        si = actual.size\n",
    "        # if hasattr(self, 'input_layer'):\n",
    "        if hasattr(self, 'output_layer'):\n",
    "            self.deactivate_ReLU()\n",
    "        else:\n",
    "            self.deactivate_softmax(actual)\n",
    "        self.input_weight.delta = self.dZ.dot(self.input_layer.A.T) / si\n",
    "        self.bias.delta = np.sum(self.dZ) / si\n",
    "            \n",
    "    def update_parameters(self, alpha):\n",
    "        if hasattr(self, 'input_layer'):\n",
    "            self.input_weight.update_data(alpha)\n",
    "            self.bias.update_data(alpha)\n",
    "            \n",
    "class Input_Layer(Layer):\n",
    "    def __init__(self, train_data, output_weight):\n",
    "        self.Z = train_data.T/255.\n",
    "        self.A = train_data.T/255.\n",
    "        self.output_weight = output_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(data_name, train_percentage):\n",
    "    data = Data(data_name)\n",
    "    data.prepare_data(train_percentage)\n",
    "    return data\n",
    "\n",
    "data_name, train_percentage = \"MNIST_dataset.csv\", 0.4\n",
    "data = importData(data_name, train_percentage)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
